---
Date: 2021-06-02
Source:
Tags: mathematics 

---
# Definição: Entropia
Dada uma variável aleatória $X$ com distribuição de probabilidade $p$, temos que sua entropia é definida como
$$H(X) \equiv - \sum\limits_{x} p(x) \log p(x)$$ 

Devido à definição de [[Def - Informação Mútua| informação mútua]], podemos dizer que a entropia é uma medida de *autoinformação* da variável $X$.

---
### References
- [[]]